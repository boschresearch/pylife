{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pylife.stress.histogram import *\n",
    "import pylife.stress.timesignal as ts\n",
    "from pylife.stress.rainflow import *\n",
    "import pylife.stress.equistress\n",
    "\n",
    "import pylife.strength.meanstress\n",
    "from pylife.strength import miner\n",
    "from pylife.strength import sn_curve\n",
    "from pylife.strength.miner import MinerElementar, MinerHaibach\n",
    "from pylife.strength import failure_probability as fp\n",
    "\n",
    "from pylife.materialdata.woehler.controls.whole_woehler_curve_plotter import  WholeWoehlerCurvePlotter\n",
    "from pylife.materialdata.woehler.diagrams.woehler_curve_diagrams import WoehlerCurveDiagrams\n",
    "from pylife.materialdata.woehler.controls.woehler_curve_data_plotter import  WoehlerCurveDataPlotter\n",
    "from pylife.materialdata.woehler.controls.woehler_curve_analyzer_options import  WoehlerCurveAnalyzerOptions\n",
    "\n",
    "import pylife.mesh.meshplot\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from IPython.display import HTML\n",
    "import base64 \n",
    "\n",
    "# mpl.style.use('seaborn')\n",
    "# mpl.style.use('seaborn-notebook')\n",
    "mpl.style.use('bmh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series signal ###\n",
    "import, filtering and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"IIS0042_DAT_2017LK065HU004_000100_0206_ESP_FA_arf_0004163.dat.csv\",\n",
    "         \"IIS0042_DAT_2017LK065HU004_000100_0206_ALC7_abf_0004587.dat.csv\",\n",
    "         \"IIS0042_DAT_2017LK065HU004_000100_0205_hfc2_abf_0003880.dat.csv\"]\n",
    "data_loc = '\\\\\\\\fe00fs76.de.bosch.com\\\\SP17_Extern$\\\\SP17-010\\\\TSIPRAS\\\\MeasuredData\\\\Messdaten_ESP_Maneuver\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = []\n",
    "for upload in files:\n",
    "    data_akt = pd.read_csv(data_loc + upload, sep = \",\")\n",
    "    if len(data_akt.columns) == 1:\n",
    "        print ('please use \",\" as seperator next time')\n",
    "        data_akt = pd.read_csv(data_loc + upload, sep = \";\")\n",
    "        input_data.append(data_akt)\n",
    "    print(upload + \" imported succesfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_resample = widgets.FloatText(value = 40e3,min=1,max=100e3,step=10,\n",
    "    description='Resampling frequency [Hz]',\n",
    "    disabled=False,readout=True,readout_format='d')\n",
    "display(f_resample)\n",
    "# select time column\n",
    "timeColumn = widgets.Dropdown(options = data_akt.columns)\n",
    "display(timeColumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_resample = []\n",
    "for file_act in input_data:\n",
    "    file_act = file_act.set_index(timeColumn.value)\n",
    "    meas_resample.append(ts.TimeSignalPrep(file_act).resample_acc(f_resample.value))\n",
    "display(file_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"select channel to plot\")\n",
    "plotChan = widgets.Dropdown(options = file_act.columns)\n",
    "display(plotChan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig, ax = plt.subplots(len(meas_resample))\n",
    "fig.suptitle('Resampled input data')\n",
    "ii = 0\n",
    "for df_act in meas_resample:\n",
    "    ax[ii].plot(df_act.index, df_act[plotChan.value])\n",
    "    ii += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_min = widgets.FloatText(value = 100,description='min frequency [Hz]',disabled=False)\n",
    "f_max = widgets.FloatText(value = 5e3,description='max frequency [Hz]',disabled=False)\n",
    "display(f_min)\n",
    "display(f_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandpass = []\n",
    "for df_act in meas_resample:\n",
    "    bandpassDF = pd.DataFrame(index = df_act.index)\n",
    "    for col_act in df_act.columns:\n",
    "        bandpassDF[col_act] = ts.TimeSignalPrep(df_act[col_act]).butter_bandpass(f_min.value,f_max.value,f_resample.value,5)\n",
    "    bandpass.append(bandpassDF) \n",
    "display(bandpassDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"select channel to for running stats\")\n",
    "runChan = widgets.Dropdown(options = df_act.columns)\n",
    "display(runChan)\n",
    "print(\" Running statistics method\")\n",
    "method_choice = widgets.Dropdown(options = ['rms','max','min','abs'])\n",
    "display(method_choice)\n",
    "\n",
    "paraRunStats = ['window_length', 'buffer_overlap', 'limit']\n",
    "values = [800,0.1,0.1]\n",
    "child = [widgets.FloatText(description=name) for name in paraRunStats]\n",
    "tab = widgets.Tab()\n",
    "tab.children = child\n",
    "for i in range(len(child)):\n",
    "    tab.set_title(i, paraRunStats[i])\n",
    "    tab.children[i].value = values[i]\n",
    "\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Running statistics to drop out zero values \"\"\"\n",
    "cleaned = []\n",
    "for df_act in bandpass:\n",
    "    cleaned_df = ts.TimeSignalPrep(df_act).running_stats_filt(\n",
    "                            col = runChan.value,\n",
    "                            window_length = int(tab.children[0].value),\n",
    "                            buffer_overlap = int(tab.children[1].value),\n",
    "                            limit = tab.children[2].value,\n",
    "                            method = method_choice.value)\n",
    "    cleaned.append(cleaned_df)\n",
    "# display(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig, ax = plt.subplots(len(meas_resample))\n",
    "fig.suptitle('Cleaned input data')\n",
    "ii = 0\n",
    "for df_act in cleaned:\n",
    "    ax[ii].plot(df_act.index, df_act[runChan.value])\n",
    "    ii += 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rainflow ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcChan = widgets.Dropdown(options = df_act.columns)\n",
    "display(rfcChan)\n",
    "binwidget = widgets.IntSlider(value = 64, min=1, max=1024, step=1,description='Bins:')\n",
    "display(binwidget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainflow = []\n",
    "for df_act in cleaned:\n",
    "    rfc = RainflowCounterFKM().process(df_act[rfcChan.value].values)\n",
    "    rfm = rfc.get_rainflow_matrix_frame(binwidget.value)\n",
    "    rainflow.append(rfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "colormap = cm.ScalarMappable()\n",
    "cmap = cm.get_cmap('PuRd')\n",
    "# fig, ax = plt.subplots(2,len(rainflow))\n",
    "fig = plt.figure(figsize = (8,11))\n",
    "fig.suptitle('Rainflow of Channel ' + rfcChan.value)\n",
    "ii = 1\n",
    "\n",
    "for rf_act in rainflow:\n",
    "    # 2D\n",
    "    ax = fig.add_subplot(3,2,2*ii-1)\n",
    "    froms = rf_act.index.get_level_values('from').mid\n",
    "    tos = rf_act.index.get_level_values('to').mid\n",
    "    counts = np.flipud((rf_act.values.reshape(rf_act.index.levshape).T))#.ravel()\n",
    "    ax.set_xlabel('From')\n",
    "    ax.set_ylabel('To')\n",
    "    ax.imshow(np.log10(counts), extent=[froms.min(), froms.max(), tos.min(), tos.max()])\n",
    "    # 3D\n",
    "    ax = fig.add_subplot(3,2,2*ii, projection='3d')\n",
    "    bottom = np.zeros_like(counts.ravel())\n",
    "    width = rf_act.index.get_level_values('from').length.min()\n",
    "    depth = rf_act.index.get_level_values('to').length.min()\n",
    "    max_height = np.max(counts.ravel())   # get range of colorbars\n",
    "    min_height = np.min(counts.ravel())\n",
    "    rgba = [cmap((k-min_height)/max_height) for k in counts.ravel()] \n",
    "    ax.set_xlabel('From')\n",
    "    ax.set_ylabel('To')\n",
    "    ax.set_zlabel('Count')\n",
    "    ax.bar3d(froms.ravel(), tos.ravel(), bottom, width, depth, counts.ravel(), shade=True, color=rgba, zsort='average')\n",
    "    ii += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meanstress transformation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanstress_para = ['M', 'M2', 'R_Goal']\n",
    "values = [0.3,0.2,-1]\n",
    "child = [widgets.FloatText(description=name) for name in meanstress_para]\n",
    "tab_mean = widgets.Tab()\n",
    "tab_mean.children = child\n",
    "for i in range(len(child)):\n",
    "    tab_mean.set_title(i, meanstress_para[i])\n",
    "    tab_mean.children[i].value = values[i]\n",
    "\n",
    "tab_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = []\n",
    "for rf_act in rainflow:\n",
    "    transformed.append(rf_act.meanstress_hist.FKM_goodman(pd.Series({'M': tab_mean.children[0].value, \n",
    "                                                                     'M2': tab_mean.children[1].value})\n",
    "                                                          , R_goal = tab_mean.children[2].value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeating factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child = [widgets.FloatText(description=name) for name in files]\n",
    "tab_repeat = widgets.Tab()\n",
    "tab_repeat.children = child\n",
    "for i in range(len(child)):\n",
    "    tab_repeat.set_title(i, files[i])\n",
    "    tab_repeat.children[i].value = 1\n",
    "tab_repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(len(files)): \n",
    "    transformed[ii] = transformed[ii]*tab_repeat.children[ii].value\n",
    "range_only_total = combine_hist(transformed,method = \"sum\")\n",
    "display(range_only_total)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(10, 5))\n",
    "# plot total\n",
    "amplitude = range_only_total.index.get_level_values('range').left.values[::-1]/2\n",
    "cycles = range_only_total.values[::-1].ravel()\n",
    "ax[0].step(cycles,amplitude,c = \"black\",linewidth = 3, label = \"total\")\n",
    "ax[1].step(np.cumsum(cycles),amplitude,c = \"black\",linewidth = 3, label = \"total\")\n",
    "ii = 0\n",
    "for range_only in transformed:\n",
    "    amplitude = range_only.index.get_level_values('range').mid.values[::-1]/2\n",
    "    cycles = range_only.values[::-1].ravel()\n",
    "    ax[0].step(cycles,amplitude,label = files [ii])\n",
    "    ax[1].step(np.cumsum(cycles),amplitude,label = files [ii])\n",
    "    ii += 1\n",
    "ax[0].set_title('Count')\n",
    "ax[1].set_title('Cumulated sum count')\n",
    "ax[1].legend()\n",
    "for ai in ax:\n",
    "    ai.xaxis.grid(True)\n",
    "    ai.set_xlabel('count')\n",
    "    ai.set_ylabel('amplitude of ' + rfcChan.value)\n",
    "    ai.set_ylim((0,max(amplitude)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nominal stress approach ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Material parameters ###\n",
    "You can create your own material data from Woeler tests using the Notebook woehler_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = pd.Series(index = ['k_1', 'ND_50', 'SD_50', '1/TN', '1/TS'],\n",
    "                data = [8, 1.5e+06, 3e+02, 12, 1.1])\n",
    "display(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Damage Calculation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNmethod = widgets.Dropdown(options = ['Miner Elementar','Miner Haibach','Miner original'])\n",
    "display(SNmethod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "damage_calc = sn_curve.FiniteLifeCurve(**mat.drop(['1/TN','1/TS']))\n",
    "damage = damage_calc.calc_damage(range_only_total,method = 'original')\n",
    "display(damage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "class wc_data:\n",
    "    def __init__(self, k, TN,loads_max):\n",
    "        self.k = k\n",
    "        self.TN = TN\n",
    "        self.loads_max = loads_max\n",
    "SRI = mat['SD_50']*(mat['ND_50']**(1/mat['k_1']))\n",
    "# wc = wc_data(mat['k_1'],mat['TN_inv'],SRI) \n",
    "_ = WoehlerCurveDiagrams(mat,[],None, y_min=1, y_max=SRI).plot_fitted_curve(k_2 = None)\n",
    "# _ = PlotWoehlerCurve.final_curve_plot(mat_para, 0,\"amp\",'ACC', \n",
    "#                                       'm/s^2',(1,1e8), (1e2,5e3),\n",
    "#                                       0)\n",
    "# plt.barh(stress_finite,np.cumsum(data_finite.values), height = data_finite.index.get_level_values('range').length.min())\n",
    "plt.step(np.cumsum(cycles),2*amplitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failure Probaility ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without field scatter ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "D50 = 0.3\n",
    "mat_std = np.log10(mat_para['TN_inv'])/2.5631031311\n",
    "dmin = d/10\n",
    "di = np.linspace(dmin,50*d,1000)\n",
    "failprob = fp.FailureProbability(D50,mat_std).pf_simple_load(di)\n",
    "#print(failprob)\n",
    "fig, ax = plt.subplots()\n",
    "ax.semilogx(di, failprob, label='cdf')\n",
    "ax.vlines(d, 0, fp.FailureProbability(D50,mat_std).pf_simple_load(d))\n",
    "# \n",
    "ix = np.linspace(dmin, d)\n",
    "ax.fill_between(ix, fp.FailureProbability(D50,mat_std).pf_simple_load(ix), y2=0,color = 'y')\n",
    "plt.xlabel(\"Damage\")\n",
    "plt.ylabel(\"cdf\")\n",
    "plt.title(\"Failure probability = %.2f\" %fp.FailureProbability(D50,mat_std).pf_simple_load(d))  \n",
    "plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With field scatter ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_std = 0.35\n",
    "fig, ax = plt.subplots()\n",
    "# plot pdf of material\n",
    "mat_pdf = norm.pdf(np.log10(di), loc=np.log10(D50), scale=mat_std)\n",
    "ax.semilogx(di, mat_pdf, label='pdf_mat')\n",
    "# plot pdf of load\n",
    "field_pdf = norm.pdf(np.log10(di), loc=np.log10(d), scale=field_std)\n",
    "ax.semilogx(di, field_pdf, label='pdf_load',color = 'r')\n",
    "# area_1\n",
    "area = np.minimum(mat_pdf, field_pdf)\n",
    "ax.fill_between(di, area, y2=0,color = 'y')\n",
    "plt.xlabel(\"Damage\")\n",
    "plt.ylabel(\"pdf\")\n",
    "plt.title(\"Failure probability = %.2f\" %fp.FailureProbability(D50,mat_std).pf_norm_load(d,field_std))  \n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local stress approach ##\n",
    "#### FE based failure probability calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'plate_with_hole.h5'\n",
    "\n",
    "stress = pd.read_hdf(filename, 'node_data')\n",
    "stress['S13'] = np.zeros_like(stress['S11'])\n",
    "stress['S23'] = np.zeros_like(stress['S11'])\n",
    "\"\"\" Equivalent stress \"\"\"\n",
    "s_vm = stress.groupby('element_id').mean().equistress.mises().rename(columns={'mises': 'sigma_a'})\n",
    "s_vm = 2*s_vm/s_vm.max()\n",
    "\"\"\" Scale with \"\"\"\n",
    "ampl = pd.DataFrame(data = data_finite.index.get_level_values('range').mid.values, columns = [\"ampl\"] ,index = data_finite[\"frequency\"].values)\n",
    "s_vm_scaled = pd.DataFrame(data = ampl.values*s_vm.transpose().values,index = ampl.index,columns = s_vm.index)\n",
    "#display(s_vm_scaled)\n",
    "#data_finite = data_act[range_mid > sn_curve_parameters[\"sigma_ak\"]][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Damage Calculation ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_vm_scaled[s_vm_scaled < mat_para['SD_50']] = 0\n",
    "N = damage_calc.sn_curve.calc_N(s_vm_scaled,ignore_limits = True)\n",
    "d_mesh_cycle =  1/(N.div(N.index.values, axis = 'index'))\n",
    "#np.sum(data_act[range_mid > sn_curve_parameters[\"sigma_ak\"]].values/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "d_mesh = d_mesh_cycle.sum()\n",
    "fig, ax = plt.subplots()\n",
    "stress.join(pd.DataFrame(data = d_mesh,columns = ['d'])).meshplot.plot(ax, 'd', cmap='jet_r')\n",
    "plt.show()\n",
    "plt.title(\"Damage per element\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d_mesh.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
