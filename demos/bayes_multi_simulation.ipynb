{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Source Software Development for Reliability and Lifetime Calculation\n",
    "## TUMWVIB Chair of Vibroacoustics of Vehicles and Machines\n",
    "#### Supervisors:  \n",
    "* Sepahvand, Kheirollah; Dr.-Ing. habil.\n",
    "* Kreuter, Daniel Christopher; Dr.-Ing\n",
    "* Mueller, Johannes; Dr.-Ing\n",
    "\n",
    "#### Student: \n",
    "Mustapha Kassem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes evaluation tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import numpy.ma as ma\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano\n",
    "theano.gof.compilelock.set_lock_status(False)\n",
    "from scipy import stats\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import mystic as my\n",
    "from os import path\n",
    "import io\n",
    "import sys, os\n",
    "import json\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from pylife.materialdata.woehler.analyzer import *\n",
    "from pylife.materialdata.woehler.bayes_analyzer import *\n",
    "\n",
    "#data = pd.read_excel(\"C:/Users/\")\n",
    "data = pd.read_excel('../pylife/materialdata/data/Test_dat.xlsx')\n",
    "data.columns=['loads', 'cycles']\n",
    "\n",
    "# Limit of the load cycle\n",
    "ld_cyc_lim = data['cycles'].max()\n",
    "#ld_cyc_lim = 10e6\n",
    "\n",
    "\n",
    "# Class WoehlerCurve\n",
    "WC_data = WoehlerCurve(data, ld_cyc_lim, {}, {'k_1': '', '1/TN': '', 'SD_50': '', '1/TS': '', 'ND_50': ''})\n",
    "\n",
    "x = np.log10(WC_data.fractures.loads)\n",
    "y = np.log10(WC_data.fractures.cycles)\n",
    "\n",
    "slope_full, intercept_full, r_value, p_value, std_err = stats.linregress(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_runs = 1\n",
    "n_N=[0,0,0,0,0,0,0,5,0,5,0,5,0,5]\n",
    "n_N_inf=[3,0,3,0,3,0,0]\n",
    "np.sum(n_N)+ np.sum(n_N_inf), WC_data.data.loads.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "for n in range(test_runs):\n",
    "    step = step + 1 \n",
    "#### DATA\n",
    "    ndraws = 5000  # number of draws from the distribution\n",
    "    nburn = 1000   # number of \"burn-in points\" (which we'll discard)\n",
    "    \n",
    "    data_small_fin = ld_lvl_sample(WC_data, data, n_N)\n",
    "    data_small_inf, data_inf_dict, n_frac = ld_lvl_sample_inf(WC_data, n_N_inf)\n",
    "\n",
    "    data_total_x = np.concatenate((data_small_fin['x'], data_small_inf['x']))\n",
    "    data_total_y = np.concatenate((data_small_fin['y'], data_small_inf['y']))\n",
    "    data_total = {'x':10**data_total_x, 'y':10**data_total_y}\n",
    "\n",
    "    dataset = pd.DataFrame(data_total)\n",
    "    dataset.columns=['loads', 'cycles']\n",
    "\n",
    "    WC_data_sub = WoehlerCurve(dataset, ld_cyc_lim, {}, \n",
    "                               {'k_1': '', '1/TN': '', 'SD_50': '', '1/TS': '', 'ND_50': ''},\n",
    "                               )\n",
    "\n",
    "    x_sub = np.log10(WC_data_sub.fractures.loads)\n",
    "    y_sub = np.log10(WC_data_sub.fractures.cycles)\n",
    "    data_small_frac = dict(x=x_sub, y=y_sub)\n",
    "\n",
    "    slope_sub, intercept_sub, r_value, p_value, std_err = stats.linregress(x_sub, y_sub)\n",
    "    \n",
    "#### k    \n",
    "    with pm.Model() as model_robust:\n",
    "        trace_robust = bayesian_slope_norm(data_dict=data_small_frac, model_name=model_robust, \n",
    "                                           samples=ndraws, chains=2)\n",
    "\n",
    "    burned_trace_robust = trace_robust[1000:]\n",
    "    pm.traceplot(burned_trace_robust)\n",
    "\n",
    "#### TN\n",
    "    with pm.Model() as WL:\n",
    "        stdev = pm.HalfNormal('stdev', sd=1.3) #sd standard wert (log-normal/ beat Verteilung/exp lambda)\n",
    "        mu = pm.Normal('mu', mu=np.log10(WC_data_sub.N_shift).mean(), sd=np.log10(WC_data_sub.N_shift).std()) #mu k√∂nnte von FKM gegeben\n",
    "\n",
    "        y = pm.Normal('y', mu=mu, sd=stdev, observed=np.log10(WC_data_sub.N_shift)) #lognormal\n",
    "\n",
    "        trace_TN = pm.sample(ndraws, nuts_kwargs={'target_accept': 0.99}, chains=3, tune=1000)\n",
    "        \n",
    "    burned_trace_TN = trace_TN[1000:]\n",
    "    #pm.traceplot(burned_trace_TN)\n",
    "    \n",
    "#### SD, TS    \n",
    "    data_S = data_small_inf['x']\n",
    "    data_N = data_small_inf['y']\n",
    "\n",
    "    # create our Op\n",
    "    logl = LogLike(mali_sum_lolli, data_S, data_N, WC_data.load_cycle_limit)\n",
    "\n",
    "    # use PyMC3 to sampler from log-likelihood\n",
    "    with pm.Model():\n",
    "        # set priors on model gradient and y-intercept\n",
    "        SD = pm.Normal('SD_50', mu=data_S.mean(), sd=data_S.std()*5)\n",
    "        #TS = pm.Exponential('TS_50', lam=1.1*2.5631031311)\n",
    "        TS = pm.Lognormal('TS_50', mu=np.log10(1.1), sd=np.log10(0.5))\n",
    "\n",
    "        # convert m and c to a tensor vector\n",
    "        var = tt.as_tensor_variable([SD, TS])\n",
    "\n",
    "        # use a DensityDist (use a lamdba function to \"call\" the Op)\n",
    "        '''pm.traceplot(trace)\n",
    "            plt.show()\n",
    "            doesnt work with density disk yet\n",
    "\n",
    "            https://discourse.pymc.io/t/pm-traceplot-error/3524\n",
    "        '''\n",
    "        pm.DensityDist('likelihood', lambda v: logl(v), observed={'v': var})\n",
    "\n",
    "        trace_SD_TS = pm.sample(ndraws, tune=nburn, chains=3, discard_tuned_samples=True)\n",
    "        \n",
    "#### DATA EXPORT\n",
    "    if step==1:\n",
    "        with open('bayes_dict_5.json', 'w') as fp:\n",
    "            json.dump({'Bayes_TS':[trace_quantiles(trace_SD_TS)[0]['TS_50'][50]/2.5631031311],\n",
    "                       'Mali_TS':[WC_data_sub.Mali_5p_result['1/TS']],\n",
    "                       'Bayes_SD':[trace_quantiles(trace_SD_TS)[0]['SD_50'][50]],\n",
    "                       'Mali_SD':[np.log10(WC_data_sub.Mali_5p_result['SD_50'])],\n",
    "                       'Bayes_TN':[trace_quantiles(burned_trace_TN)[0]['stdev'][50]],\n",
    "                       'Mali_TN':[WC_data_sub.Mali_5p_result['1/TN']]},fp)\n",
    "                       'Bayes_k':-[trace_quantiles(burned_trace_robust)[0]['x'][50]],\n",
    "                       'Mali_k':[WC_data_sub.Mali_5p_result['k_1']]},fp)\n",
    "    else:\n",
    "        with open('bayes_dict_5.json', 'r') as fp:\n",
    "            dict_import = json.load(fp)\n",
    "        with open('bayes_dict_5.json', 'w') as feedsjson:\n",
    "            dict_import['Bayes_TS'].append(trace_quantiles(trace_SD_TS)[0]['TS_50'][50]/2.5631031311)\n",
    "            dict_import['Bayes_SD'].append(trace_quantiles(trace_SD_TS)[0]['SD_50'][50])\n",
    "            dict_import['Bayes_TN'].append(trace_quantiles(burned_trace_TN)[0]['mu'][50])\n",
    "            dict_import['Bayes_k'].append(trace_quantiles(burned_trace_robust)[0]['x'][50])\n",
    "            dict_import['Mali_TS'].append(WC_data_sub.Mali_5p_result['1/TS'])\n",
    "            dict_import['Mali_SD'].append(np.log10(WC_data_sub.Mali_5p_result['SD_50']))\n",
    "            dict_import['Mali_TN'].append(WC_data_sub.Mali_5p_result['1/TN'])\n",
    "            dict_import['Mali_k'].append(WC_data_sub.Mali_5p_result['k_1'])\n",
    "\n",
    "            json.dump(dict_import, feedsjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bayes_dict.json', 'r') as fp:\n",
    "    dict_import = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "sorted_data = dict_import['Bayes_TS'].sort()\n",
    "mu = np.mean(dict_import['Bayes_TS'])\n",
    "std = np.std(dict_import['Bayes_TS'])\n",
    "ax = fig.add_subplot(111, xlabel='x', ylabel='y', title='Generated data and underlying model of 1/TS')\n",
    "ax.plot(np.arange(len(dict_import['Bayes_TS'])),stats.norm.cdf(dict_import['Bayes_TS'], mu, std),  'g')\n",
    "#plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111, xlabel='x', ylabel='y', title='Generated data and underlying model of 1/TS')\n",
    "ax.plot(np.arange(len(dict_import['Bayes_TS'])), \n",
    "        np.ones(len(dict_import['Mali_TS']))*np.mean(np.array([*dict_import['Bayes_TS']])*2.5631031311),  'g')\n",
    "ax.plot( np.arange(len(dict_import['Mali_TS'])),\n",
    "        np.ones(len(dict_import['Mali_TS']))*np.mean(dict_import['Mali_TS']), 'r')\n",
    "\n",
    "ax.plot(np.arange(len(dict_import['Bayes_TS'])),np.array([*dict_import['Bayes_TS']])*2.5631031311,  'gx', label='Bayes_TS')\n",
    "ax.plot( np.arange(len(dict_import['Mali_TS'])),dict_import['Mali_TS'], 'rx', label='Mali_TS')\n",
    "ax.plot(np.arange(len(dict_import['Mali_TS'])),\n",
    "        np.ones(len(dict_import['Mali_TS']))*WC_data.Mali_5p_result['1/TS'],'b', label='Full')\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111, xlabel='x', ylabel='y', title='Generated data and underlying model of SD')\n",
    "ax.plot(np.arange(len(dict_import['Bayes_SD'])), \n",
    "        np.ones(len(dict_import['Mali_SD']))*np.mean(dict_import['Bayes_SD']),  'g')\n",
    "ax.plot( np.arange(len(dict_import['Mali_SD'])),\n",
    "        np.ones(len(dict_import['Mali_SD']))*np.mean(dict_import['Mali_SD']), 'r')\n",
    "\n",
    "ax.plot(np.arange(len(dict_import['Bayes_SD'])), dict_import['Bayes_SD'],  'gx', label='Bayes_SD')\n",
    "ax.plot(np.arange(len(dict_import['Mali_SD'])),dict_import['Mali_SD'], 'rx', label='Mali_SD')\n",
    "ax.plot(np.arange(len(dict_import['Mali_SD'])),\n",
    "        np.ones(len(dict_import['Mali_SD']))*np.log10(WC_data.Mali_5p_result['SD_50']),'b', label='Full')\n",
    "plt.legend(loc=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111, xlabel='x', ylabel='y', title='Generated data and underlying model of 1/TN')\n",
    "ax.plot(np.arange(len(dict_import['Bayes_TN'])), dict_import['Bayes_TN'],  'gx', label='Bayes_TN')\n",
    "ax.plot( np.arange(len(dict_import['Mali_TN'])),dict_import['Mali_TN'], 'rx', label='Mali_TN')\n",
    "\n",
    "ax.plot(np.arange(len(dict_import['Bayes_TN'])), \n",
    "        np.ones(len(dict_import['Mali_TN']))*np.mean(dict_import['Bayes_TN']),  'g')\n",
    "ax.plot( np.arange(len(dict_import['Mali_TN'])),\n",
    "        np.ones(len(dict_import['Mali_TN']))*np.mean(dict_import['Mali_TN']), 'r')\n",
    "ax.plot(np.arange(len(dict_import['Mali_TN'])),\n",
    "        np.ones(len(dict_import['Mali_TN']))*WC_data.Mali_5p_result['1/TN'],'b', \n",
    "        label='Full %f'%WC_data.Mali_5p_result['1/TN'])\n",
    "#ax.set_yscale('log')\n",
    "plt.legend(loc=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111, xlabel='x', ylabel='y', title='Generated data and underlying model of slope k')\n",
    "ax.plot(np.arange(len(dict_import['Bayes_k'])), \n",
    "        dict_import['Bayes_k']*np.ones(len(dict_import['Bayes_k']))*-1,  'gx', label='Bayes_k')\n",
    "ax.plot( np.arange(len(dict_import['Mali_k'])),dict_import['Mali_k'], 'rx', label='Mali_k')\n",
    "\n",
    "ax.plot(np.arange(len(dict_import['Bayes_k'])), \n",
    "        np.mean(dict_import['Bayes_k'])*np.ones(len(dict_import['Bayes_k']))*-1,  'g')\n",
    "ax.plot( np.arange(len(dict_import['Mali_k'])),\n",
    "        np.mean(dict_import['Mali_k'])*np.ones(len(dict_import['Bayes_k'])), 'r')\n",
    "ax.plot(np.arange(len(dict_import['Mali_k'])),\n",
    "        np.ones(len(dict_import['Mali_k']))*WC_data.Mali_5p_result['k_1'],'b', label='Full')\n",
    "plt.legend(loc=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    with open('bayes_dict.json', 'w') as fp:\n",
    "        json.dump({'Bayes_TS':[trace_quantiles(trace_SD_TS)[0]['TS_50'][50]/2.5631031311],\n",
    "                   'Mali_TS':[WC_data_sub.Mali_5p_result['1/TS']],\n",
    "                   'Bayes_SD':[trace_quantiles(trace_SD_TS)[0]['SD_50'][50]],\n",
    "                   'Mali_SD':[np.log10(WC_data_sub.Mali_5p_result['SD_50'])],\n",
    "                   'Bayes_TN':[trace_quantiles(burned_trace_TN)[0]['stdev'][50]],\n",
    "                   'Mali_TN':[WC_data_sub.Mali_5p_result['1/TN']],\n",
    "                   'Bayes_k':-[trace_quantiles(burned_trace_robust)[0]['x'][50]],\n",
    "                   'Mali_k':[WC_data_sub.Mali_5p_result['k_1']]},fp)\n",
    "                   \n",
    "    with open('bayes_dict_5.json', 'r') as fp:\n",
    "        dict_import = json.load(fp)\n",
    "    with open('bayes_dict.json', 'w') as feedsjson:\n",
    "        dict_import['Bayes_TS'].append(trace_quantiles(trace_SD_TS)[0]['TS_50'][50]/2.5631031311)\n",
    "        dict_import['Bayes_SD'].append(trace_quantiles(trace_SD_TS)[0]['SD_50'][50])\n",
    "        dict_import['Bayes_TN'].append(trace_quantiles(burned_trace_TN)[0]['stdev'][50])\n",
    "        dict_import['Bayes_k'].append(trace_quantiles(burned_trace_robust)[0]['x'][50])\n",
    "        dict_import['Mali_TS'].append(WC_data_sub.Mali_5p_result['1/TS'])\n",
    "        dict_import['Mali_SD'].append(np.log10(WC_data_sub.Mali_5p_result['SD_50']))\n",
    "        dict_import['Mali_TN'].append(WC_data_sub.Mali_5p_result['1/TN'])\n",
    "        dict_import['Mali_k'].append(WC_data_sub.Mali_5p_result['k_1'])\n",
    "\n",
    "        json.dump(dict_import, feedsjson)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
