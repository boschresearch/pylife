{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Life time Calculation ###\n",
    "This Notebook shows a general calculation stream for a nominal and local stress reliability approach.\n",
    "#### Stress derivation #####\n",
    "First we read in different time signals (coming from a test bench or a vehicle measurement e.g.).\n",
    "\n",
    "1. Import the time series into a pandas Data Frame\n",
    "2. Resample the time series if necessary\n",
    "3. Filter the time series with a bandpass filter if necessary\n",
    "4. Edititing time series using Running Statistics methods\n",
    "5. Rainflow Calculation\n",
    "6. Mean stress correction\n",
    "7. Multiplication with repeating factor of every manoveur\n",
    "\n",
    "#### Damage Calculation ####\n",
    "1. Select the damage calculation method (Miner elementary, Miner-Haibach, ...)\n",
    "2. Calculate the damage for every load level and the damage sum\n",
    "3. Calculate the failure probability with or w/o field scatter\n",
    "\n",
    "#### Local stress approach ####\n",
    "1. Load the FE mesh\n",
    "2. Apply the load history to the FE mesh\n",
    "3. Calculate the damage\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pylife.stress.histogram import *\n",
    "import pylife.stress.timesignal as ts\n",
    "from pylife.stress.rainflow import *\n",
    "import pylife.stress.equistress\n",
    "\n",
    "import pylife.strength.meanstress\n",
    "from pylife.strength import miner\n",
    "from pylife.strength import sn_curve\n",
    "from pylife.strength.miner import MinerElementar, MinerHaibach\n",
    "from pylife.strength import failure_probability as fp\n",
    "import pylife.vmap\n",
    "\n",
    "import pyvista as pv\n",
    "\n",
    "from pylife.materialdata.woehler.diagrams.woehler_curve_diagrams import WoehlerCurveDiagrams\n",
    "\n",
    "import pylife.mesh.meshplot\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from IPython.display import HTML\n",
    "import base64 \n",
    "\n",
    "# mpl.style.use('seaborn')\n",
    "# mpl.style.use('seaborn-notebook')\n",
    "mpl.style.use('bmh')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series signal ###\n",
    "import, filtering and so on. You can import your own signal with\n",
    "\n",
    "* [pd.read_csv()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)\n",
    "* [pd.read_excel()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html)\n",
    "* [scipy.io.loadmat()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.loadmat.html) for matlab files \n",
    "\n",
    "and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0,60,60*2048)\n",
    "files = ['wn','sine']\n",
    "wn = pd.DataFrame(index = t, columns = ['sensor_1'], data = 120*np.random.randn(len(t)))\n",
    "sine = pd.DataFrame(index = t, columns = ['sensor_1'], data = 80*np.sin(2*np.pi*50*t))\n",
    "input_data = [wn,sine]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = []\n",
    "# for upload in files:\n",
    "#     data_akt = pd.read_csv(data_loc + upload, sep = \",\")\n",
    "#     if len(data_akt.columns) == 1:\n",
    "#         print ('please use \",\" as seperator next time')\n",
    "#         data_akt = pd.read_csv(data_loc + upload, sep = \";\")\n",
    "#         input_data.append(data_akt)\n",
    "#     print(upload + \" imported succesfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_resample = widgets.FloatText(value = 1024,min=1,max=100e3,step=1,\n",
    "    description='Resampling frequency [Hz]',\n",
    "    disabled=False,readout=True,readout_format='d')\n",
    "display(f_resample)\n",
    "# select time column\n",
    "# timeColumn = widgets.Dropdown(options = data_akt.columns)\n",
    "# display(timeColumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_resample = []\n",
    "for file_act in input_data:\n",
    "#     file_act = file_act.set_index(timeColumn.value)\n",
    "    meas_resample.append(ts.TimeSignalPrep(file_act).resample_acc(f_resample.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"select channel to plot\")\n",
    "plotChan = widgets.Dropdown(options = file_act.columns)\n",
    "display(plotChan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(meas_resample))\n",
    "fig.suptitle('Resampled input data')\n",
    "ii = 0\n",
    "for df_act in meas_resample:\n",
    "    if len(meas_resample) == 1:\n",
    "        ax.plot(df_act.index, df_act[plotChan.value])  \n",
    "    else:\n",
    "        ax[ii].plot(df_act.index, df_act[plotChan.value])\n",
    "    ii += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_min = widgets.FloatText(value = 5,description='min frequency [Hz]',disabled=False)\n",
    "f_max = widgets.FloatText(value = 100,description='max frequency [Hz]',disabled=False)\n",
    "display(f_min)\n",
    "display(f_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandpass = []\n",
    "for df_act in meas_resample:\n",
    "    bandpassDF = pd.DataFrame(index = df_act.index)\n",
    "    for col_act in df_act.columns:\n",
    "        bandpassDF[col_act] = ts.TimeSignalPrep(df_act[col_act]).butter_bandpass(f_min.value,f_max.value,f_resample.value,5)\n",
    "    bandpass.append(bandpassDF) \n",
    "display(bandpassDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"select channel to for running stats\")\n",
    "runChan = widgets.Dropdown(options = df_act.columns)\n",
    "display(runChan)\n",
    "print(\" Running statistics method\")\n",
    "method_choice = widgets.Dropdown(options = ['rms','max','min','abs'])\n",
    "display(method_choice)\n",
    "\n",
    "paraRunStats = ['window_length', 'buffer_overlap', 'limit']\n",
    "values = [800,0.1,0.015]\n",
    "child = [widgets.FloatText(description=name) for name in paraRunStats]\n",
    "tab = widgets.Tab()\n",
    "tab.children = child\n",
    "for i in range(len(child)):\n",
    "    tab.set_title(i, paraRunStats[i])\n",
    "    tab.children[i].value = values[i]\n",
    "\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Running statistics to drop out zero values \"\"\"\n",
    "cleaned = []\n",
    "for df_act in bandpass:\n",
    "    cleaned_df = ts.TimeSignalPrep(df_act).running_stats_filt(\n",
    "                            col = runChan.value,\n",
    "                            window_length = int(tab.children[0].value),\n",
    "                            buffer_overlap = int(tab.children[1].value),\n",
    "                            limit = tab.children[2].value,\n",
    "                            method = method_choice.value)\n",
    "    cleaned.append(cleaned_df)\n",
    "# display(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"select channel to plot\")\n",
    "plotChan = widgets.Dropdown(options = file_act.columns)\n",
    "display(plotChan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(meas_resample))\n",
    "fig.suptitle('Cleaned input data')\n",
    "for i, df_act in enumerate(cleaned):\n",
    "    if len(meas_resample) == 1:\n",
    "        ax.plot(df_act.index, df_act[plotChan.value])  \n",
    "    else:\n",
    "        ax[i].plot(df_act.index, df_act[plotChan.value])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rainflow ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcChan = widgets.Dropdown(options = df_act.columns)\n",
    "display(rfcChan)\n",
    "binwidget = widgets.IntSlider(value = 64, min=1, max=1024, step=1,description='Bins:')\n",
    "display(binwidget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainflow = []\n",
    "for df_act in cleaned:\n",
    "    rfc = RainflowCounterFKM().process(df_act[rfcChan.value].values)\n",
    "    rfm = rfc.get_rainflow_matrix_frame(binwidget.value)\n",
    "    rainflow.append(rfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = cm.ScalarMappable()\n",
    "cmap = cm.get_cmap('PuRd')\n",
    "# fig, ax = plt.subplots(2,len(rainflow))\n",
    "fig = plt.figure(figsize = (8,11))\n",
    "fig.suptitle('Rainflow of Channel ' + rfcChan.value)\n",
    "\n",
    "for i, rf_act in enumerate(rainflow):\n",
    "    # 2D\n",
    "    ax = fig.add_subplot(3,2,2*(i+1)-1)\n",
    "    froms = rf_act.index.get_level_values('from').mid\n",
    "    tos = rf_act.index.get_level_values('to').mid\n",
    "    counts = np.flipud((rf_act.values.reshape(rf_act.index.levshape).T))#.ravel()\n",
    "    ax.set_xlabel('From')\n",
    "    ax.set_ylabel('To')\n",
    "    ax.imshow(np.log10(counts), extent=[froms.min(), froms.max(), tos.min(), tos.max()])\n",
    "    # 3D\n",
    "    ax = fig.add_subplot(3,2,2*(i+1), projection='3d')\n",
    "    bottom = np.zeros_like(counts.ravel())\n",
    "    width = rf_act.index.get_level_values('from').length.min()\n",
    "    depth = rf_act.index.get_level_values('to').length.min()\n",
    "    max_height = np.max(counts.ravel())   # get range of colorbars\n",
    "    min_height = np.min(counts.ravel())\n",
    "    rgba = [cmap((k-min_height)/max_height) for k in counts.ravel()] \n",
    "    ax.set_xlabel('From')\n",
    "    ax.set_ylabel('To')\n",
    "    ax.set_zlabel('Count')\n",
    "    ax.bar3d(froms.ravel(), tos.ravel(), bottom, width, depth, counts.ravel(), shade=True, color=rgba, zsort='average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meanstress transformation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanstress_para = ['M', 'M2', 'R_Goal']\n",
    "values = [0.3,0.2,-1]\n",
    "child = [widgets.FloatText(description=name) for name in meanstress_para]\n",
    "tab_mean = widgets.Tab()\n",
    "tab_mean.children = child\n",
    "for i in range(len(child)):\n",
    "    tab_mean.set_title(i, meanstress_para[i])\n",
    "    tab_mean.children[i].value = values[i]\n",
    "\n",
    "tab_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = []\n",
    "for rf_act in rainflow:\n",
    "    transformed.append(rf_act.meanstress_hist.FKM_goodman(pd.Series({'M': tab_mean.children[0].value, \n",
    "                                                                     'M2': tab_mean.children[1].value})\n",
    "                                                          , R_goal = tab_mean.children[2].value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeating factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child = [widgets.FloatText(description=name) for name in files]\n",
    "tab_repeat = widgets.Tab()\n",
    "tab_repeat.children = child\n",
    "for i in range(len(child)):\n",
    "    tab_repeat.set_title(i, files[i])\n",
    "    tab_repeat.children[i].value = int(50/(i+1))\n",
    "tab_repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(len(files)): \n",
    "    transformed[ii] = transformed[ii]*tab_repeat.children[ii].value\n",
    "range_only_total = combine_hist(transformed,method = \"sum\")\n",
    "display(range_only_total)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(10, 5))\n",
    "# plot total\n",
    "amplitude = range_only_total.index.get_level_values('range').left.values[::-1]/2\n",
    "cycles = range_only_total.values[::-1].ravel()\n",
    "ax[0].step(cycles,amplitude,c = \"black\",linewidth = 3, label = \"total\")\n",
    "ax[1].step(np.cumsum(cycles),amplitude,c = \"black\",linewidth = 3, label = \"total\")\n",
    "ii = 0\n",
    "for range_only in transformed:\n",
    "    amplitude = range_only.index.get_level_values('range').mid.values[::-1]/2\n",
    "    cycles = range_only.values[::-1].ravel()\n",
    "    ax[0].step(cycles,amplitude,label = files [ii])\n",
    "    ax[1].step(np.cumsum(cycles),amplitude,label = files [ii])\n",
    "    ii += 1\n",
    "ax[0].set_title('Count')\n",
    "ax[1].set_title('Cumulated sum count')\n",
    "ax[1].legend()\n",
    "for ai in ax:\n",
    "    ai.xaxis.grid(True)\n",
    "    ai.set_xlabel('count')\n",
    "    ai.set_ylabel('amplitude of ' + rfcChan.value)\n",
    "    ai.set_ylim((0,max(amplitude)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nominal stress approach ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Material parameters ###\n",
    "You can create your own material data from Woeler tests using the Notebook woehler_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = pd.Series(index = ['k_1', 'ND_50', 'SD_50', '1/TN', '1/TS'],\n",
    "                data = [8, 1.5e+06, 1.5e+02, 12, 1.1])\n",
    "display(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Damage Calculation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNmethod = widgets.Dropdown(options = ['Miner Elementar','Miner Haibach','Miner original'])\n",
    "display(SNmethod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "damage_calc = sn_curve.FiniteLifeCurve(**mat.drop(['1/TN','1/TS']))\n",
    "damage = damage_calc.calc_damage(range_only_total,method = 'original')\n",
    "# display(damage)\n",
    "print(\"\\033[5m  Total Damage of channel %s: %.2e  \\033[0m\" % (rfcChan.value,damage.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRI = mat['SD_50']*(mat['ND_50']**(1/mat['k_1']))\n",
    "# Plotting\n",
    "diagdata = WoehlerCurveDiagrams(mat, fatigue_data = None, analyzer = None,\n",
    "                                y_min=2, y_max=SRI, x_min=1e1, x_max=1e12, ax = None)\n",
    "diagdata.plot_fitted_curve( k_2=15)\n",
    "plt.step(np.cumsum(cycles),2*amplitude)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failure Probaility ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without field scatter ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D50 = 0.05\n",
    "d = damage.sum()\n",
    "di = np.logspace(np.log10(1e-1*d),np.log10(1e3*d),1000).flatten()\n",
    "std = np.log10(mat['1/TN'])/2.5631031311\n",
    "failprob = fp.FailureProbability(D50,std).pf_simple_load(di)\n",
    "#print(failprob)\n",
    "fig, ax = plt.subplots()\n",
    "ax.semilogx(di, failprob, label='cdf')\n",
    "ax.vlines(d, max(failprob), fp.FailureProbability(D50,std).pf_simple_load(d))\n",
    "# \n",
    "plt.xlabel(\"Damage\")\n",
    "plt.ylabel(\"cdf\")\n",
    "plt.title(\"Failure probability = %.2e\" %fp.FailureProbability(D50,std).pf_simple_load(d))  \n",
    "plt.ylim(0,max(failprob))\n",
    "plt.xlim(min(di),max(di))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With field scatter ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_std = 0.35\n",
    "fig, ax = plt.subplots()\n",
    "# plot pdf of material\n",
    "mat_pdf = norm.pdf(np.log10(di), loc=np.log10(D50), scale=std)\n",
    "ax.semilogx(di, mat_pdf, label='pdf_mat')\n",
    "# plot pdf of load\n",
    "field_pdf = norm.pdf(np.log10(di), loc=np.log10(d), scale=field_std)\n",
    "ax.semilogx(di, field_pdf, label='pdf_load',color = 'r')\n",
    "plt.xlabel(\"Damage\")\n",
    "plt.ylabel(\"pdf\")\n",
    "plt.title(\"Failure probability = %.2e\" %fp.FailureProbability(D50,std).pf_norm_load(d,field_std))  \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local stress approach ##\n",
    "#### FE based failure probability calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_mesh = pylife.vmap.VMAP(\"plate_with_hole.vmap\")\n",
    "pyLife_mesh = (vm_mesh.make_mesh('1', 'STATE-2')\n",
    "               .join_coordinates()\n",
    "               .join_variable('STRESS_CAUCHY')\n",
    "               .join_variable('DISPLACEMENT')\n",
    "               .to_frame())\n",
    "\n",
    "pyLife_mesh.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent stress range\n",
    "pyLife_mesh['mises'] = 2*pyLife_mesh.equistress.mises()\n",
    "# Scaling with amplitude\n",
    "pyLife_mesh['mises'] = 2*pyLife_mesh['mises']/pyLife_mesh['mises'].max()\n",
    "ampl_fe = pd.DataFrame(data = amplitude, columns = [\"ampl\"] ,index =cycles)\n",
    "s_vm_scaled = pd.DataFrame(data = ampl_fe.values*pyLife_mesh['mises'].transpose().values,index = ampl_fe.index,columns = pyLife_mesh['mises'].index)\n",
    "display(s_vm_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Damage Calculation ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = damage_calc.calc_N(s_vm_scaled,ignore_limits = True)\n",
    "d_mesh_cycle =  1/(N.div(N.index.values, axis = 'index'))\n",
    "#np.sum(data_act[range_mid > sn_curve_parameters[\"sigma_ak\"]].values/N)\n",
    "\n",
    "d_mesh = d_mesh_cycle.sum()\n",
    "display(d_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLife_mesh = pyLife_mesh.join(pd.DataFrame(data = d_mesh,columns = ['d']))\n",
    "display(pyLife_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting using pyvista\n",
    "pyLife_nodes = pyLife_mesh.groupby('node_id').mean()\n",
    "mesh = pv.PolyData(pyLife_nodes[['x', 'y', 'z']].values)\n",
    "mesh.point_arrays[\"d\"] = pyLife_nodes[\"d\"].values\n",
    "mesh.plot(scalars=\"d\",log_scale = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximal damage sum: %f\" % d_mesh.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
