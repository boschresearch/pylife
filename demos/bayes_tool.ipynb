{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Open Source Software Development for Reliability and Lifetime Calculation\n",
    "## TUMWVIB Chair of Vibroacoustics of Vehicles and Machines\n",
    "#### Supervisors:  \n",
    "* Sepahvand, Kheirollah; Dr.-Ing. habil.\n",
    "* Kreuter, Daniel Christopher; Dr.-Ing\n",
    "* Mueller, Johannes; Dr.-Ing\n",
    "\n",
    "#### Student: \n",
    "Mustapha Kassem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes evaluation tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.ma as ma\n",
    "from scipy import stats, optimize\n",
    "import mystic as my\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from os import path\n",
    "import io\n",
    "import sys, os\n",
    "import json\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from pylife.materialdata.woehler.fatigue_data import FatigueData\n",
    "from pylife.materialdata.woehler.woehler_curve_creator import WoehlerCurveCreator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes theory\n",
    "\n",
    "\\begin{equation}\n",
    "P(H | D)=\\frac{P(D | H) \\, P(H)}{P(D)}\n",
    "\\end{equation}\n",
    "\n",
    "- $P(H | D)$ is the posterior distribution, the sought probability of event $H$ occurring given that event $D$ is given or true.\n",
    "- $P(D | H)$ is the likelihood distribution, the likelihood of event $D$ occurring given event $H$.\n",
    "- $P(H)$ and $P(D)$ are the marginal probabilities of events $H$ and $D$ independent of one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The posterior is equal to the likelihood of the data times the prior for the model parameters divided by a normalization constant. \n",
    "<br>\n",
    "- If we have some domain knowledge, we can use it to assign priors for the model parameters, or we can use non-informative priors: distributions with large standard deviations that do not assume anything about the variable. \n",
    "<br>\n",
    "- Using a non-informative prior means we “let the data speak.” A common prior choice is to use a normal distribution for β and a half-cauchy distribution for σ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To build a Bayesian model there are three steps\n",
    "\n",
    "### 1. Define priors\n",
    "The priors are the desired parameters that are to be sampled. They are defined as statistical distributions (normal, exponential etc). The statistical distribution is an assumption about the parameter\n",
    "\n",
    "### 2. Define likelihood function(s)\n",
    "The likelihood function is the function that defines the relationship the priors must fulfil in order to best fit the observed data of the model.\n",
    "\n",
    "### 3. Inference\n",
    "Lastly, the inference is where the number of samples are generated. The sampler used is called the No-U Turn Sampler (NUTS), which is a Markov chain Monte Carlo algorithm. The inference does not produce only one best fitted parameter, compared to the Maximum likelihood estimation, but a vast range of posterior distributions for the parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import theano\n",
    "theano.gof.compilelock.set_lock_status(False)\n",
    "import theano.tensor as tt\n",
    "\n",
    "from pylife.materialdata.woehler.utils.bayes_analyzer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WC model from FKM data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"C:/Users/KSS7RNG/Desktop/Masterarbeit_KASSEM/Pylife/Test_dat.xlsx\")\n",
    "#data = pd.read_excel('../data/Test_dat.xlsx')\n",
    "data.columns=['loads', 'cycles']\n",
    "\n",
    "# Limit of the load cycle\n",
    "ld_cyc_lim = data['cycles'].max()\n",
    "\n",
    "# Class WoehlerCurve\n",
    "fatigue_data = FatigueData(data, ld_cyc_lim)\n",
    "woehler_curve_creator = WoehlerCurveCreator(fatigue_data)\n",
    "Bayes_data = woehler_curve_creator.maximum_like_procedure({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.log10(fatigue_data.fractures.loads)\n",
    "y = np.log10(fatigue_data.fractures.cycles)\n",
    "\n",
    "fig = plt.figure(figsize=(4,5.5))\n",
    "ax = fig.add_subplot(111, xlabel='x', ylabel='y', title='Generated data and underlying model')\n",
    "ax.plot(y, x, 'x', label='%d Failures'%(len(fatigue_data.fractures.loads)))\n",
    "plt.plot(np.log10(fatigue_data.runouts.cycles), np.log10(fatigue_data.runouts.loads), 'bo', mfc='none', \n",
    "         label=u'%d Runouts'%(len(fatigue_data.runouts.loads)),alpha=0.5)\n",
    "plt.xlabel(\"Load-cycle (N)\", fontsize=11)\n",
    "plt.ylabel(\"Load (S)\", fontsize=11)\n",
    "plt.legend(loc=0);\n",
    "plt.ylim(2.44,2.58)\n",
    "plt.xlim(min(y)*0.96,max(y)*1.04)\n",
    "destination_path='C:\\\\Users\\\\KSS7RNG\\\\Desktop\\\\Masterarbeit_KASSEM\\\\Latex\\\\AMlatex\\\\AMStudentThesis\\\\results\\\\Bayes\\\\'\n",
    "name = \"bayes_fullsys_tight\"\n",
    "plt.savefig(destination_path+name+'.eps', format='eps', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data points from full system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_N=[0,0,0,0,0,0,0,5,0,5,0,5,0,5]\n",
    "n_N_inf=[3,0,3,0,3,0,0]\n",
    "\n",
    "ndraws = 3000  # number of draws from the distribution\n",
    "nburn = 1000   # number of \"burn-in points\" (which we'll discard)\n",
    "\n",
    "data_small_fin = ld_lvl_sample(Bayes_data, data, n_N)\n",
    "data_small_inf, data_inf_dict, n_frac = ld_lvl_sample_inf(Bayes_data, n_N_inf)\n",
    "\n",
    "data_total_x = np.concatenate((data_small_fin['x'], data_small_inf['x']))\n",
    "data_total_y = np.concatenate((data_small_fin['y'], data_small_inf['y']))\n",
    "data_total = {'x':10**data_total_x, 'y':10**data_total_y}\n",
    "\n",
    "dataset = pd.DataFrame(data_total)\n",
    "dataset.columns=['loads', 'cycles']\n",
    "\n",
    "fatigue_data_sub = FatigueData(dataset)\n",
    "woehler_curve_creator_sub = WoehlerCurveCreator(fatigue_data_sub)\n",
    "Bayes_data_sub = woehler_curve_creator_sub.maximum_like_procedure({})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sub = np.log10(fatigue_data_sub.fractures.loads)\n",
    "y_sub = np.log10(fatigue_data_sub.fractures.cycles)\n",
    "data_sub = dict(x=x_sub, y=y_sub)\n",
    "\n",
    "fig = plt.figure(figsize=(4, 5.5))\n",
    "ax = fig.add_subplot(111, xlabel='x', ylabel='y', title='Generated data and underlying model')\n",
    "ax.plot(y_sub, x_sub, 'x', label='%d Failures'%(len(fatigue_data_sub.fractures.loads)))\n",
    "plt.plot(np.log10(fatigue_data_sub.runouts.cycles), np.log10(fatigue_data_sub.runouts.loads), 'bo', mfc='none', \n",
    "         label=u'%d Runouts'%(len(fatigue_data_sub.runouts.loads)), alpha=0.5)\n",
    "plt.xlabel(\"Load-cycle (N)\", fontsize=11)\n",
    "plt.ylabel(\"Load (S)\", fontsize=11)\n",
    "plt.legend(loc=0)\n",
    "plt.ylim(2.44,2.58)\n",
    "plt.xlim(min(y)*0.96,max(y)*1.04)\n",
    "destination_path='C:\\\\Users\\\\KSS7RNG\\\\Desktop\\\\Masterarbeit_KASSEM\\\\Latex\\\\AMlatex\\\\AMStudentThesis\\\\results\\\\Bayes\\\\'\n",
    "name = \"bayes_subsys_tight\"\n",
    "plt.savefig(destination_path+name+'.eps', format='eps', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian tool models:\n",
    "\n",
    "1. Slope $k_1$\n",
    "2. Scatter in load-cycle direction $\\frac{1}{T_N}$\n",
    "3. Endurance $SD_{50}$ Scatter in load direction $\\frac{1}{T_S}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slope $k_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as slope:\n",
    "    sigma = pm.HalfCauchy('sigma', beta=10, testval=1.)\n",
    "    intercept = pm.Normal('Intercept', 0, sigma=20)\n",
    "    x_coeff = pm.Normal('x', 0, sigma=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as slope:\n",
    "    likelihood = pm.Normal('y', mu=intercept + x_coeff * x, sigma=sigma, observed=y_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as slope:\n",
    "    trace_robust = pm.sample(3000,  chains=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLM built in function for linear regression in pymc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = {\"sd\": pm.HalfCauchy.dist(beta=10, testval=1.),\n",
    "          \"Intercept\": pm.Normal.dist(mu=0, sigma=20),\n",
    "          \"x\": pm.Normal.dist(mu=0, sigma=20)\n",
    "          }\n",
    "with pm.Model() as slope:\n",
    "    pm.glm.GLM.from_formula('y ~ x', data_sub, priors = priors)\n",
    "    trace_slope = pm.sample(6000, nuts_kwargs={'target_accept': 0.99}, chains=3, tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Fig\n",
    "fig = pm.model_to_graphviz(slope)\n",
    "destination_path='C:\\\\Users\\\\'\n",
    "name = \"slope_model\"\n",
    "fig.render(destination_path+name, view=False, format='eps')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burned_trace_slope = trace_slope[1000:]\n",
    "pm.traceplot(burned_trace_slope)\n",
    "# Saving Fig\n",
    "fig = plt.gcf() # to get the current figure...\n",
    "name = \"k1_convergence\"\n",
    "fig.savefig(destination_path+name+'.eps', view=False, format='eps') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_quantiles(x):\n",
    "\n",
    "    return pd.DataFrame(pm.quantiles(x, [5, 50, 95]))\n",
    "\n",
    "pm.stats.summary(burned_trace_slope, start=1000, stat_funcs=[trace_quantiles, trace_sd, monte]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_slope_plot(data_sub, burned_trace_slope, \n",
    "                    fatigue_data_sub.a_wl , fatigue_data_sub.b_wl, \n",
    "                    fatigue_data.a_wl, fatigue_data.b_wl)\n",
    "name = \"k1_samples_plot\"\n",
    "plt.savefig(destination_path+name+'.eps', format='eps', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Full SYS %d data points:'%fatigue_data.fractures.shape[0])\n",
    "print('Mali Value:         ', Bayes_data.curve_parameters['k_1'])\n",
    "print('\\nSub SYS %d data points:'% fatigue_data_sub.fractures.shape[0])\n",
    "print('Bayes MC estimation:', abs(trace_quantiles(burned_trace_slope)[0]['x'][50]))\n",
    "print('Mali Value:         ', Bayes_data_sub.curve_parameters['k_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter $\\frac{1}{T_N}$ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as TN:\n",
    "    \n",
    "    # Priors\n",
    "    stdev = pm.Exponential('stdev', lam=1/5)\n",
    "    mu = pm.Normal('mu', mu=np.log10(fatigue_data_sub.N_shift).mean(), sd=10)\n",
    "    \n",
    "    # Likelihood\n",
    "    y = pm.Normal('y', mu=mu, sd=stdev, observed=np.log10(fatigue_data_sub.N_shift))\n",
    "    \n",
    "    # Inference\n",
    "    trace_TN = pm.sample(7000, nuts_kwargs={'target_accept': 0.99}, chains=4, tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving fig\n",
    "name = \"TN_model\"\n",
    "fig_TN= pm.model_to_graphviz(TN)\n",
    "fig_TN.render(destination_path+name, view=False, format='eps')\n",
    "fig_TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burned_trace_TN = trace_TN[1000:]\n",
    "pm.traceplot(burned_trace_TN)\n",
    "# saving fig\n",
    "fig = plt.gcf() # to get the current figure...\n",
    "name = \"TN_convergence\"\n",
    "fig.savefig(destination_path+name+'.eps', view=False, format='eps') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.stats.summary(trace_TN, start=1000, stat_funcs=[trace_quantiles, trace_sd, monte]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Full SYS %d data points:'%fatigue_data.fractures.shape[0])\n",
    "print('Pearl chain:        ', fatigue_data.TN)\n",
    "print('Mali Value:         ', Bayes_data.curve_parameters['1/TN'])\n",
    "print('\\nSub SYS %d data points:'% fatigue_data_sub.fractures.shape[0])\n",
    "print('Bayes MC estimation:', trace_quantiles(burned_trace_TN)[0]['mu'][50])\n",
    "print('Mali Value:         ', Bayes_data_sub.curve_parameters['1/TN'])\n",
    "print('Pearl chain:        ', fatigue_data_sub.TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infinite Zone: $SD_{50}$, $TS_{50}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_S = data_small_inf['x']\n",
    "data_N = data_small_inf['y']\n",
    "\n",
    "# create our Op\n",
    "logl = LogLike(mali_sum_lolli, data_S, data_N, fatigue_data.load_cycle_limit)\n",
    "\n",
    "# use PyMC3 to sampler from log-likelihood\n",
    "with pm.Model() as inf_zone:\n",
    "    \n",
    "    # Priors\n",
    "    SD = pm.Normal('SD_50', mu=data_S.mean(), sd=data_S.std()*5)\n",
    "    TS = pm.Exponential('TS_50', lam=1/1.1)\n",
    "    #TS = pm.Lognormal('TS_50', mu=np.log10(1.1), sd=np.log10(0.5))\n",
    "    # convert SD and TS to a tensor vector\n",
    "    var = tt.as_tensor_variable([SD, TS])\n",
    "\n",
    "    # Likelihood\n",
    "    pm.DensityDist('likelihood', lambda v: logl(v), observed={'v': var})\n",
    "    \n",
    "    # Inference\n",
    "    trace_SD_TS = pm.sample(5000, tune=1000, chains=3, discard_tuned_samples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.stats.summary(trace_SD_TS, stat_funcs=[trace_quantiles, trace_sd, monte]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Full SYS data points:',fatigue_data.zone_inf.shape[0])\n",
    "print('Sub SYS data points:  ', len(data_small_inf['x']))\n",
    "\n",
    "print('\\nMali FUll Sys TS:', Bayes_data.curve_parameters['1/TS']) \n",
    "print('Bayes SUB Sys TS:',(trace_quantiles(trace_SD_TS)[0]['TS_50'][50]/2.5631031311))\n",
    "print('Mali SUB Sys TS: ', Bayes_data_sub.curve_parameters['1/TS']) \n",
    "\n",
    "print('\\nMali FUll Sys SD:', np.log10(Bayes_data.curve_parameters['SD_50']))\n",
    "print('Bayes SUB Sys SD:',trace_quantiles(trace_SD_TS)[0]['SD_50'][50])\n",
    "print('Mali SUB Sys SD: ', np.log10(Bayes_data_sub.curve_parameters['SD_50']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results of bayes_multi_simulation Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bayes_dict.json', 'r') as fp:\n",
    "    dict_import = json.load(fp)\n",
    "dict_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111, xlabel='x', ylabel='y', title='Generated data and underlying model of 1/TS')\n",
    "ax.plot(np.arange(len(dict_import['Bayes_TS'])), \n",
    "        np.ones(len(dict_import['Mali_TS']))*np.mean(dict_import['Bayes_TS']),  'g')\n",
    "ax.plot( np.arange(len(dict_import['Mali_TS'])),\n",
    "        np.ones(len(dict_import['Mali_TS']))*np.mean(dict_import['Mali_TS']), 'r')\n",
    "\n",
    "ax.plot(np.arange(len(dict_import['Bayes_TS'])),dict_import['Bayes_TS'],  'gx', label='Bayes_TS')\n",
    "ax.plot( np.arange(len(dict_import['Mali_TS'])),dict_import['Mali_TS'], 'rx', label='Mali_TS')\n",
    "ax.plot(np.arange(len(dict_import['Mali_TS'])),\n",
    "        np.ones(len(dict_import['Mali_TS']))*Bayes_data.curve_parameters['1/TS'],'b', label='Full')\n",
    "plt.legend(loc=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111, xlabel='x', ylabel='y', title='Generated data and underlying model of SD')\n",
    "ax.plot(np.arange(len(dict_import['Bayes_SD'])), \n",
    "        np.ones(len(dict_import['Mali_SD']))*np.mean(dict_import['Bayes_SD']),  'g')\n",
    "ax.plot( np.arange(len(dict_import['Mali_SD'])),\n",
    "        np.ones(len(dict_import['Mali_SD']))*np.mean(dict_import['Mali_SD']), 'r')\n",
    "\n",
    "ax.plot(np.arange(len(dict_import['Bayes_SD'])), dict_import['Bayes_SD'],  'gx', label='Bayes_SD')\n",
    "ax.plot(np.arange(len(dict_import['Mali_SD'])),dict_import['Mali_SD'], 'rx', label='Mali_SD')\n",
    "ax.plot(np.arange(len(dict_import['Mali_SD'])),\n",
    "        np.ones(len(dict_import['Mali_SD']))*np.log10(Bayes_data.curve_parameters['SD_50']),'b', label='Full')\n",
    "plt.legend(loc=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111, xlabel='x', ylabel='y', title='Generated data and underlying model of slope k')\n",
    "ax.plot(np.arange(len(dict_import['Bayes_k'])), \n",
    "        dict_import['Bayes_k']*np.ones(len(dict_import['Bayes_k']))*-1,  'gx', label='Bayes_k')\n",
    "ax.plot( np.arange(len(dict_import['Mali_k'])),dict_import['Mali_k'], 'rx', label='Mali_k')\n",
    "\n",
    "ax.plot(np.arange(len(dict_import['Bayes_k'])), \n",
    "        np.mean(dict_import['Bayes_k'])*np.ones(len(dict_import['Bayes_k']))*-1,  'g')\n",
    "ax.plot( np.arange(len(dict_import['Mali_k'])),\n",
    "        np.mean(dict_import['Mali_k'])*np.ones(len(dict_import['Bayes_k'])), 'r')\n",
    "ax.plot(np.arange(len(dict_import['Mali_k'])),\n",
    "        np.ones(len(dict_import['Mali_k']))*Bayes_data.curve_parameters['k_1'],'b', label='Full')\n",
    "plt.legend(loc=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111, xlabel='x', ylabel='y', title='Generated data and underlying model of 1/TN')\n",
    "ax.plot(np.arange(len(dict_import['Bayes_TN'])), dict_import['Bayes_TN'],  'gx', label='Bayes_TN')\n",
    "ax.plot( np.arange(len(dict_import['Mali_TN'])),dict_import['Mali_TN'], 'rx', label='Mali_TN')\n",
    "\n",
    "ax.plot(np.arange(len(dict_import['Bayes_TN'])), \n",
    "        np.ones(len(dict_import['Mali_TN']))*np.mean(dict_import['Bayes_TN']),  'g')\n",
    "ax.plot( np.arange(len(dict_import['Mali_TN'])),\n",
    "        np.ones(len(dict_import['Mali_TN']))*np.mean(dict_import['Mali_TN']), 'r')\n",
    "ax.plot(np.arange(len(dict_import['Mali_TN'])),\n",
    "        np.ones(len(dict_import['Mali_TN']))*Bayes_data.curve_parameters['1/TN'],'b', \n",
    "        label='Full %f'%Bayes_data.curve_parameters['1/TN'])\n",
    "#ax.set_yscale('log')\n",
    "plt.legend(loc=0);"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}