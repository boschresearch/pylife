{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series handling  \n",
    "\n",
    "This Notebook shows a general calculation stream for time series. You will see how to \n",
    "* read in time series\n",
    "* plot the data in time and frequency domain\n",
    "* filter the time series with a bandpass filter\n",
    "* remove spikes using running statistics\n",
    "* calculate and plot the rainflow matrices of the time series\n",
    "* combine the PSD to an envelope PSD.\n",
    "\n",
    "If you have any question feel free to contact [us](mailto:DanielChristopher.Kreuter@de.bosch.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pylife.utils.histogram as psh\n",
    "import pylife.stress.timesignal as ts\n",
    "import pylife.stress.rainflow as RF\n",
    "import pylife.stress.rainflow.recorders as RFR\n",
    "import pickle\n",
    "\n",
    "import pyvista as pv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "\n",
    "from scipy import signal as sg\n",
    "\n",
    "# mpl.style.use('seaborn')\n",
    "mpl.style.use('bmh')\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some functionality to plot the rainflow matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import plot_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series signal ###\n",
    "import, filtering and so on. You can import your own signal with\n",
    "\n",
    "* [pd.read_csv()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)\n",
    "* [pd.read_excel()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html)\n",
    "* [scipy.io.loadmat()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.loadmat.html) for matlab files \n",
    "\n",
    "and so on. Here we define a white noise, a sine and a sine on random signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4711)\n",
    "sample_frequency = 1024\n",
    "t = np.linspace(0, 60, 60 * sample_frequency)\n",
    "signal_df = pd.DataFrame(data = np.array([80 * np.random.randn(len(t)),\n",
    "                                          160 * np.sin(2 * np.pi * 50 * t)]).T,\n",
    "                         columns=[\"wn\", \"sine\"],\n",
    "                         index=pd.Index(t, name=\"time\"))\n",
    "signal_df[\"SoR\"] = signal_df[\"wn\"] + signal_df[\"sine\"]\n",
    "signal_df.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.psd_df(signal_df, nfft = 512).plot(loglog=True, ylabel=\"PSD\", title=\"PSD of time series\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering \n",
    "We are using a butterworth bandpass filter from [scipy.signal](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.butter.html) to filter the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_min = 5.0    # Hz\n",
    "f_max = 100.0  # Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandpass_df = ts.butter_bandpass(signal_df, f_min, f_max)\n",
    "\n",
    "df_psd = ts.psd_df(bandpass_df, nfft = 512)\n",
    "df_psd.plot(loglog=True, ylabel=\"PSD bandpassed\", title=\"PSD of filtered time series\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a spike in our existing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandpass_df[\"spiky\"] = bandpass_df[\"sine\"] + 1e4 * sg.unit_impulse(signal_df.shape[0], idx=\"mid\")\n",
    "bandpass_df.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to clean this spike automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = ts.clean_timeseries(bandpass_df, \"spiky\", window_size=1024, overlap=32,\n",
    "                     feature=\"maximum\", method=\"remove\", n_gridpoints=3,\n",
    "                     percentage_max=0.05, order=3).drop([\"time\"], axis=1)\n",
    "\n",
    "cleaned_df.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rainflow ###\n",
    "The [rainflow module](https://pylife.readthedocs.io/en/latest/stress/rainflow.html) in pyLife can be used with different counting methods:\n",
    "\n",
    "* FKM\n",
    "* Three point\n",
    "* Four point enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainflow_bins = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Rainflow for a multiple time series\n",
    "recorder_dict = {key: RFR.FullRecorder() for key in cleaned_df}\n",
    "detector_dict = {key: RF.FKMDetector(recorder=recorder_dict[key]).process(cleaned_df[key]) for key in cleaned_df}\n",
    "rf_series_dict = {key: detector_dict[key].recorder.histogram(rainflow_bins) for  key in detector_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot_rf(rf_series_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Now Combining different RFs to one\n",
    "rf_series_dict[\"wn + sn\"] = psh.combine_histogram([rf_series_dict[\"wn\"],rf_series_dict[\"sine\"]],\n",
    "                                                  method=\"sum\")\n",
    "f = plot_rf(rf_series_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the difference of the rainflow matrices of *SoR* and *wn+sn*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSD combinig\n",
    "It is also possible to combine spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_psd[\"envelope\"] =  df_psd[[\"sine\", \"wn\"]].max(axis = 1)\n",
    "df_psd.plot(loglog=True, ylabel=\"PSD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving\n",
    "\n",
    "Now we saving the rainflow data into a pickle file.\n",
    "If you want to have an introduction to damage and failure probability calculation, please have a look on the notebook [lifetime_calc](lifetime_calc.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_dict = {k: rf_series_dict[k] for k in [\"wn\", \"sine\", \"SoR\"] if k in rf_series_dict}\n",
    "%store rf_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
